- import_role:
    name: cloudalchemy.prometheus
  vars:
    prometheus_scrape_configs: "{{ lookup('ansible.builtin.template', 'scrape_configs.j2') | from_yaml }}"
    prometheus_alertmanager_config:
      - scheme: http
        static_configs:
          - targets:
            - "127.0.0.1:9093"
    prometheus_alert_rules:
      - alert: Watchdog
        expr: vector(1)
        for: 1m
        labels:
          severity: warning
        annotations:
          description: "Watchdog"
          summary: 'Ensure entire alerting pipeline is functional'
      - alert: InstanceDown
        expr: 'up == 0'
        for: 5m
        labels:
          severity: critical
        annotations:
          description: '{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.{% endraw %}'
          summary: '{% raw %}Instance {{ $labels.instance }} down{% endraw %}'
      - alert: HostOutOfMemory
        expr: "(\n node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < {{ prometheus_mem_avail_alert_percent }}\n)\n"
        annotations:
          description: '{% raw %}Low available memory on {{ $labels.job }}.{% endraw %}'
          summary: 'Less than {{ prometheus_mem_avail_alert_percent }}% of available RAM.'
        for: 5m
        labels:
          severity: critical
      - alert: NodeFilesystemSpaceFillingUp
        annotations:
          description: '{% raw %}Filesystem on {{ $labels.device }} mounted on {{ $labels.mountpoint }} at {{ $labels.job }} has only {{ printf "%.2f" $value }}% available space left and is filling up fast.{% endraw %}'
          summary: 'Filesystem is predicted to run out of space within the next 4 hours.'
        expr: "(\n node_filesystem_avail_bytes{fstype!=\"\"} / node_filesystem_size_bytes{fstype!=\"\"} * 100 < 20\nand\n  predict_linear(node_filesystem_avail_bytes{fstype!=\"\"}[6h], 4*60*60) < 0\nand\n  node_filesystem_readonly{fstype!=\"\"} == 0\n)\n"
        for: 15m
        labels:
          severity: critical
      - alert: NodeFilesystemAlmostOutOfSpace
        annotations:
          description: '{% raw %}Filesystem on {{ $labels.device }} mounted on {{ $labels.mountpoint }} at {{ $labels.job }} has only {{ printf "%.2f" $value }}% available space left.{% endraw %}'
          summary: 'Filesystem has less than {{ prometheus_filesystem_avail_alert_percent }}% space left.'
        expr: "(\n node_filesystem_avail_bytes{fstype!=\"\"} / node_filesystem_size_bytes{fstype!=\"\"} * 100 < {{ prometheus_filesystem_avail_alert_percent }}\nand\n  node_filesystem_readonly{fstype!=\"\"} == 0\n)\n"
        for: 15m
        labels:
          severity: critical
      - alert: NodeFilesystemFilesFillingUp
        annotations:
          description: '{% raw %}Filesystem on {{ $labels.device }} mounted on {{ $labels.mountpoint }} at {{ $labels.job }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up fast.{% endraw %}'
          summary: 'Filesystem is predicted to run out of inodes within the next 4 hours.'
        expr: "(\n node_filesystem_files_free{fstype!=\"\"} / node_filesystem_files{fstype!=\"\"} * 100 < 20\nand\n  predict_linear(node_filesystem_files_free{fstype!=\"\"}[6h], 4*60*60) < 0\nand\n  node_filesystem_readonly{fstype!=\"\"} == 0\n)\n"
        for: 15m
        labels:
          severity: critical
      - alert: NodeFilesystemAlmostOutOfFiles
        annotations:
          description: '{% raw %}Filesystem on {{ $labels.device }} mounted on {{ $labels.mountpoint }} at {{ $labels.job }} has only {{ printf "%.2f" $value }}% available inodes left.{% endraw %}'
          summary: 'Filesystem has less than {{ prometheus_inodes_avail_alert_percent }}% inodes left.'
        expr: "(\n node_filesystem_files_free{fstype!=\"\"} / node_filesystem_files{fstype!=\"\"} * 100 < {{ prometheus_inodes_avail_alert_percent }}\nand\n  node_filesystem_readonly{fstype!=\"\"} == 0\n)\n"
        for: 15m
        labels:
          severity: critical
      - alert: NodeNetworkReceiveErrs
        annotations:
          description: '{% raw %}{{ $labels.job }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.{% endraw %}'
          summary: 'Network interface is reporting many receive errors.'
        expr: "increase(node_network_receive_errs_total[2m]) > 10"
        for: 15m
        labels:
          severity: warning
      - alert: NodeNetworkTransmitErrs
        annotations:
          description: '{% raw %}{{ $labels.job }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.{% endraw %}'
          summary: 'Network interface is reporting many transmit errors.'
        expr: "increase(node_network_transmit_errs_total[2m]) > 10"
        for: 15m
        labels:
          severity: warning
      - alert: HostSystemdServiceCrashed
        expr: "(\n node_systemd_unit_state{state=\"failed\",name=~\"{{ prometheus_service_alert }}\"} == 1\n)\n"
        for: 0m
        labels:
          severity: critical
        annotations:
          description: '{% raw %}systemd service {{ $labels.name }} on {{ $labels.job }} crashed.{% endraw %}'
          summary: 'Host systemd service crashed'
      - alert: HostOomKillDetected
        expr: "(\n increase(node_vmstat_oom_kill[1m]) > 0\n)"
        for: 0m
        labels:
          severity: warning
        annotations:
          description: '{% raw %}OOM kill detected\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}.{% endraw %}'
          summary: 'Host OOM kill detected'
      # Cosmos
      - alert: DelegatedTokensAmountChanged
        expr: "(\n round(delta(cosmos_validator_tokens[5m])) > {{ prometheus_delegated_token_notify_threshold }}\n)"
        for: 0m
        labels:
          severity: warning
        annotations:
          description: '{% raw %}Validator {{ $labels.moniker }} tokens on {{ $labels.chain_id }} has changed by {{ $value }}.{% endraw %}'
          summary: "Cosmos validator staked tokens change"
      - alert: WalletBalanceLow
        expr: "(\n cosmos_wallet_balance < {{ prometheus_wallet_tokens_low_alert_threshold }}\n)"
        for: 0m
        labels:
          severity: critical
        annotations:
          description: '{% raw %}Wallet {{ $labels.address }} on {{ $labels.chain_id }} has only {{ $value }}{{ $labels.denom }}.{% endraw %}'
          summary: "Cosmos wallet balance low"
      - alert: MissedBlocksChanged
        expr: "(\n round(delta(cosmos_validator_missed_blocks[5m])) > {{ prometheus_missed_blocks_threshold }}\n)"
        for: 0m
        labels:
          severity: warning
        annotations:
          description: '{% raw %}Validator {{ $labels.moniker }} missed blocks value on {{ $labels.chain_id }} has changed by {{ $value }}.{% endraw %}'
          summary: "Cosmos validator missed blocks"
      - alert: Validator not active
        expr: "(\n cosmos_validator_active == 0\n)"
        for: 0m
        labels:
          severity: critical
        annotations:
          description: '{% raw %}Validator {{ $labels.moniker }} on {{ $labels.chain_id }} is not active.{% endraw %}'
          summary: "Cosmos validator not active"
      - alert: Validator jailed
        expr: "(\n cosmos_validator_jailed == 1\n)"
        for: 0m
        labels:
          severity: critical
        annotations:
          description: '{% raw %}Validator {{ $labels.moniker }} on {{ $labels.chain_id }} is jailed.{% endraw %}'
          summary: "Cosmos validator is jailed"
